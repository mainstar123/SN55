#!/usr/bin/env python3
"""
Simple Supremacy Training
Streamlined training pipeline to achieve >90% directional accuracy
"""

import torch
import torch.nn as nn
import numpy as np
import json
from datetime import datetime
import os
import argparse

class SimpleSupremacyTrainer:
    """Simplified trainer focused on achieving >90% directional accuracy"""

    def __init__(self, target_accuracy: float = 0.90):
        self.target_accuracy = target_accuracy
        self.best_accuracy = 0.0

        print("üèÜ SIMPLE SUPREMACY TRAINING")
        print("=" * 50)
        print(".1f")
        print("üí™ Goal: Secure #1 position on subnet 55")
    def create_advanced_ensemble_model(self):
        """Create advanced ensemble model for supremacy"""

        class SupremacyEnsemble(nn.Module):
            def __init__(self):
                super().__init__()

                # Multi-model ensemble
                self.gru = nn.GRU(24, 128, num_layers=2, batch_first=True, dropout=0.2)
                self.transformer = nn.TransformerEncoder(
                    nn.TransformerEncoderLayer(24, 8, batch_first=True),
                    num_layers=3
                )
                self.cnn = nn.Sequential(
                    nn.Conv1d(1, 64, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv1d(64, 128, 3, padding=1),
                    nn.ReLU(),
                    nn.AdaptiveAvgPool1d(1),
                    nn.Flatten()
                )

                # Confidence weighting
                self.confidence_net = nn.Sequential(
                    nn.Linear(128*3, 128),
                    nn.ReLU(),
                    nn.Linear(128, 3),
                    nn.Sigmoid()
                )

                # Dynamic thresholding
                self.threshold_net = nn.Sequential(
                    nn.Linear(128*3, 64),
                    nn.ReLU(),
                    nn.Linear(64, 1),
                    nn.Sigmoid()
                )

                # Final prediction
                self.final_layer = nn.Linear(128*3, 1)

            def forward(self, x):
                # Get predictions from each model
                gru_out, _ = self.gru(x)
                gru_out = gru_out[:, -1, :]  # Last hidden state

                # Add sequence dimension for transformer
                x_seq = x.unsqueeze(1)  # (batch, 1, features)
                transformer_out = self.transformer(x_seq)
                transformer_out = transformer_out.mean(dim=1)  # Pool

                cnn_out = self.cnn(x.transpose(1, 2))

                # Concatenate
                combined = torch.cat([gru_out, transformer_out, cnn_out], dim=-1)

                # Confidence weights
                confidences = self.confidence_net(combined)

                # Dynamic threshold
                threshold = 0.5 + 0.4 * self.threshold_net(combined)

                # Weighted ensemble
                weights = torch.softmax(confidences, dim=-1)
                ensemble_out = combined * weights

                # Final prediction
                prediction = torch.sigmoid(self.final_layer(ensemble_out))

                return {
                    'prediction': prediction,
                    'confidence': confidences.mean(dim=-1),
                    'threshold': threshold,
                    'weights': weights
                }

        return SupremacyEnsemble()

    def generate_training_data(self):
        """Generate synthetic training data for demonstration"""
        print("\nüìä GENERATING TRAINING DATA...")

        np.random.seed(42)
        n_samples = 5000
        n_features = 24

        # Generate realistic market-like data
        X = np.random.randn(n_samples, n_features).astype(np.float32)

        # Add temporal patterns (trend + noise)
        time_steps = np.arange(n_samples)
        trend = 0.01 * time_steps
        seasonal = 0.1 * np.sin(2 * np.pi * time_steps / 100)
        noise = 0.05 * np.random.randn(n_samples)

        y = trend + seasonal + noise
        y = (y - y.min()) / (y.max() - y.min())  # Normalize to 0-1
        y = y.astype(np.float32)

        # Split data
        train_size = int(0.7 * n_samples)
        val_size = int(0.2 * n_samples)

        X_train = torch.from_numpy(X[:train_size])
        y_train = torch.from_numpy(y[:train_size])
        X_val = torch.from_numpy(X[train_size:train_size+val_size])
        y_val = torch.from_numpy(y[train_size:train_size+val_size])
        X_test = torch.from_numpy(X[train_size+val_size:])
        y_test = torch.from_numpy(y[train_size+val_size:])

        print(f"   ‚úÖ Generated {n_samples} samples")
        print(f"   üìà Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")

        return (X_train, y_train), (X_val, y_val), (X_test, y_test)

    def directional_accuracy_loss(self, predictions, targets):
        """Custom loss function optimized for directional accuracy"""
        if len(predictions) < 2:
            return torch.tensor(0.0, requires_grad=True)

        # Calculate directional changes
        pred_changes = predictions[1:] - predictions[:-1]
        target_changes = targets[1:] - targets[:-1]

        # Direction prediction accuracy
        pred_direction = (pred_changes > 0).float()
        target_direction = (target_changes > 0).float()

        # Binary cross entropy on directional accuracy
        loss = nn.functional.binary_cross_entropy(pred_direction, target_direction)

        return loss

    def calculate_directional_accuracy(self, predictions, targets):
        """Calculate directional accuracy metric"""
        if len(predictions) < 2 or len(targets) < 2:
            return 0.0

        pred_direction = predictions[1:] > predictions[:-1]
        target_direction = targets[1:] > targets[:-1]

        accuracy = (pred_direction == target_direction).float().mean().item()
        return accuracy

    def train_for_supremacy(self):
        """Complete supremacy training pipeline"""
        print("\nüöÄ STARTING SUPREMACY TRAINING PIPELINE")
        print("=" * 60)

        # Create model
        model = self.create_advanced_ensemble_model()
        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)

        # Generate data
        train_data, val_data, test_data = self.generate_training_data()
        X_train, y_train = train_data
        X_val, y_val = val_data

        # Training loop
        print("\nüéØ PHASE 1: ADVANCED ENSEMBLE TRAINING")
        print("-" * 50)

        best_val_accuracy = 0.0
        patience = 20
        patience_counter = 0

        for epoch in range(100):
            model.train()
            epoch_loss = 0.0
            epoch_accuracy = 0.0
            batch_count = 0

            # Training batches
            for i in range(0, len(X_train), 32):
                batch_X = X_train[i:i+32]
                batch_y = y_train[i:i+32]

                optimizer.zero_grad()

                outputs = model(batch_X)
                predictions = outputs['prediction'].squeeze()

                loss = self.directional_accuracy_loss(predictions, batch_y)
                loss.backward()
                optimizer.step()

                batch_accuracy = self.calculate_directional_accuracy(predictions.detach().numpy(), batch_y.numpy())
                epoch_loss += loss.item()
                epoch_accuracy += batch_accuracy
                batch_count += 1

            # Validation
            model.eval()
            with torch.no_grad():
                val_outputs = model(X_val)
                val_predictions = val_outputs['prediction'].squeeze().numpy()
                val_accuracy = self.calculate_directional_accuracy(val_predictions, y_val.numpy())

            avg_train_accuracy = epoch_accuracy / batch_count
            avg_train_loss = epoch_loss / batch_count

            print(f"Epoch {epoch+1:3d} | Train Acc: {avg_train_accuracy:.4f} | Val Acc: {val_accuracy:.4f} | Loss: {avg_train_loss:.4f}")

            # Check for improvement
            if val_accuracy > best_val_accuracy:
                best_val_accuracy = val_accuracy
                patience_counter = 0

                # Save best model
                if val_accuracy >= self.target_accuracy:
                    self.save_supremacy_model(model, val_accuracy)
                    print(f"   üéØ TARGET ACHIEVED: {val_accuracy:.4f} >= {self.target_accuracy:.4f}")
                    return True
            else:
                patience_counter += 1

            if patience_counter >= patience:
                print(f"   ‚èπÔ∏è Early stopping at epoch {epoch+1}")
                break

        # Final evaluation
        print("\nüéØ PHASE 2: FINAL EVALUATION")
        print("-" * 50)

        X_test, y_test = test_data
        model.eval()

        with torch.no_grad():
            test_outputs = model(X_test)
            test_predictions = test_outputs['prediction'].squeeze().numpy()
            test_accuracy = self.calculate_directional_accuracy(test_predictions, y_test.numpy())

        print("\nüèÜ FINAL RESULTS:")
        print(".4f")
        print(".4f")
        if test_accuracy >= self.target_accuracy:
            print("   üéØ SUPREMACY ACHIEVED! Ready for #1 position!")
            self.save_supremacy_model(model, test_accuracy)
            return True
        else:
            print(f"   üìà Close to target: {test_accuracy:.4f} vs {self.target_accuracy:.4f}")
            print("   üîÑ Consider additional training or architecture tweaks")
            return False

    def save_supremacy_model(self, model, accuracy):
        """Save the supremacy model"""
        checkpoint = {
            'model_state_dict': model.state_dict(),
            'accuracy': accuracy,
            'target_achieved': accuracy >= self.target_accuracy,
            'timestamp': datetime.now().isoformat(),
            'supremacy_version': '1.0'
        }

        filename = f"supremacy_model_{accuracy:.4f}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
        torch.save(checkpoint, filename)

        # Also save as latest
        latest_filename = "latest_supremacy_model.pth"
        torch.save(checkpoint, latest_filename)

        print(f"   üíæ Model saved: {filename}")
        print(f"   üíæ Latest model: {latest_filename}")

def main():
    parser = argparse.ArgumentParser(description="Simple Supremacy Training")
    parser.add_argument("--target", type=float, default=0.90,
                       help="Target directional accuracy (default: 0.90)")

    args = parser.parse_args()

    trainer = SimpleSupremacyTrainer(target_accuracy=args.target)

    try:
        success = trainer.train_for_supremacy()

        if success:
            print("\nüéØ SUPREMACY TRAINING COMPLETE!")
            print("   üèÜ >90% directional accuracy achieved!")
            print("   üí™ Ready to dominate subnet 55!")
        else:
            print("\nüìà Training complete but target not achieved.")
            print("   üîÑ Consider the suggested improvements.")

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Training interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Training failed: {e}")

if __name__ == "__main__":
    print("üèÜ SUPREMACY TRAINING SYSTEM")
    print("=" * 50)
    print("üéØ Objective: Achieve >90% directional accuracy")
    print("üí™ Goal: Secure #1 position on subnet 55")
    print("‚ö° Features: Advanced ensemble, confidence weighting, dynamic thresholding")
    print("=" * 50)

    main()
